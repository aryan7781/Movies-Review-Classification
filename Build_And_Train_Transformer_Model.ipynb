{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Build And Train Transformer Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <center> **Transformer - Attention Is All You Need !!!**  </center>\n",
        "\n",
        "<div class=\"row\">\n",
        "  <div class=\"column\" style = \" float: center; width: 100%; padding: 5px\">\n",
        "    <img src=\"https://www.analyticsinsight.net/wp-content/uploads/2022/05/Know-About-Transformer-Machine-learning-Model-at-a-Glance-1440x564_c.jpg\" alt=\"Positional Embedding in Encoder\" style=\"height:100%\">\n",
        "  </div>\n",
        "</div>"
      ],
      "metadata": {
        "id": "MEHMwtudDG3K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download Necessary Packages"
      ],
      "metadata": {
        "id": "0Chu4MQ_CrBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import nltk\n",
        "from collections import Counter\n",
        "import contractions\n",
        "import re\n",
        "from nltk import sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ],
      "metadata": {
        "id": "YXkRzdMCCpIv"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect Google Colab TPU"
      ],
      "metadata": {
        "id": "QBRJCj0uCvv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['TPU_NAME']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "apGQs_Y2CwrP",
        "outputId": "b17a42cf-10a9-4b45-9dfb-3703764687c6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'grpc://10.50.101.114:8470'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tpu_address = os.environ['TPU_NAME']\n",
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu_address)\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "\n",
        "strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "print(f\"TPU with address-  {tpu.cluster_spec().as_dict()['worker']} successfully connected\")\n",
        "print(f\"Number Of Accelerators- {strategy.num_replicas_in_sync}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCvYG24sCyyP",
        "outputId": "48007af2-a247-4639-a6e6-761a66682b7f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.50.101.114:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.50.101.114:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TPU with address-  ['10.50.101.114:8470'] successfully connected\n",
            "Number Of Accelerators- 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "7FFGm0xkIGCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_MATRIX = np.load('./Embedding_Matrix.npy')\n",
        "X_train = np.load('./X_train.npy')\n",
        "Y_train = np.load('./Y_train.npy')\n",
        "X_val = np.load('./X_val.npy')\n",
        "Y_val = np.load('./Y_val.npy')"
      ],
      "metadata": {
        "id": "0HKp4t0PI_jF"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train = Y_train.reshape((-1, 1))\n",
        "Y_val = Y_val.reshape((-1, 1))"
      ],
      "metadata": {
        "id": "9kE5otK1UUBc"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(X_train))\n",
        "print(X_train.shape, Y_train.shape)\n",
        "print(X_val.shape, Y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoFQ3A9aJfFL",
        "outputId": "44e155c8-80c6-4420-8a1f-8c000cfcbc19"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(30000, 1024) (30000, 1)\n",
            "(10000, 1024) (10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "MAX_SEQ_LEN = 1024\n",
        "EMB_DIMS = 300\n",
        "VOCAB_SIZE = EMBEDDING_MATRIX.shape[0]"
      ],
      "metadata": {
        "id": "G4vyEsIgIHqV"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).shuffle(30000).batch(BATCH_SIZE)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, Y_val)).shuffle(10000).take(5000)"
      ],
      "metadata": {
        "id": "zphTzpvVI8qw"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <center style = 'font-family:\"courier\"'> **Transformer Encoder** </center>\n",
        "<center>\n",
        "    <img src = \"https://www.researchgate.net/publication/334288604/figure/fig1/AS:778232232148992@1562556431066/The-Transformer-encoder-structure.ppm\"> </img>\n",
        "    </cener>"
      ],
      "metadata": {
        "id": "H-R6EoknA20Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align = \"justify\" style = 'font-family = \"courier\"'>Simple RNN Networks like GRUs or LSTMs do not work very well for long sentences. Simply put forward, it is difficult to keep all the information learnt in a single vector (the activation vector, **a** of the model for long sentences. After certain timesteps, the previous information tends to be lost, while current ones being captured. To address this issue, **Attention Mechanism** was introduced which took the NLP research with a storm. Everything was about **Attention** then.\n",
        "In 2017 a research paper was published, namely **Attention Is All You Need**. This was when Transformers came into existance. Transformers tried to combine the characteristics of **Convolutional Neural Networks and Attention Mechanism**. \n",
        "One main difference  between other architectures and transformer is that the **input sequence can be passed parallelly** so that GPU can be used effectively and the speed of training can also be increased. It is also based on the multi-headed attention layer, so it easily overcomes the vanishing gradient issue. Transformers made **Vectorization** possible for working on Text Data and thus increasing the speed of of training.</p>"
      ],
      "metadata": {
        "id": "ks0aK4rLBX1W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Positional Embeddings\n",
        "<p align = \"justify\">In the earlier approach, for sequential models, inputs were fed in sequence, so the effect of positions were automatically captured by the learning algorithm. But, in **Transformer Architecture**, inputs were all fed at once, so making it difficult for the architecture to guess the impact of position of a word in the sentence/paragraph. Thus, **Positional Encodings** were brought in.\n",
        "The Inputs after being converted into Embedded Matrices are added with the positional embedding matrix for the architecture to have knowledge about the position of the words.\n",
        "\n",
        "    \n",
        "<div class=\"row\">\n",
        "  <div class=\"column\" style = \" float: left; width: 30%; padding: 5px\">\n",
        "    <img src=\"https://vaclavkosar.com/images/transformer-positional-embeddings.png\" alt=\"Positional Embedding in Encoder\">\n",
        "  </div>\n",
        "  <div class=\"column\" style = \"float: left; width: 50%; padding: 5px\">\n",
        "    <img src=\"https://jinglescode.github.io/assets/img/posts/illustrated-guide-transformer-10.jpg\" alt=\"Embeddings working\">\n",
        "  </div>\n",
        "</div>"
      ],
      "metadata": {
        "id": "vq8T8hC2Baif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_positional_embedding(num_positions:int, dimensions:int):\n",
        "    \"\"\"\n",
        "    num_positions: Length Of Sequences in the dataset after padding\n",
        "    dimensions: Number of dimensions used to represent each word in embedding matrix\n",
        "    \"\"\"\n",
        "    # Create a column vector for positions\n",
        "    pos_vec = np.arange(num_positions)[:, np.newaxis]\n",
        "    \n",
        "    # Create a row vector for dimensions\n",
        "    dims_vec = np.arange(dimensions)[np.newaxis, :]\n",
        "    \n",
        "    i = pos_vec // 2\n",
        "    angles = pos_vec * 1.0 / (pow(10_000, 2 * i / dimensions))\n",
        "    angles[:, 0::2] = np.sin(angles[:, 0::2])\n",
        "    angles[:, 0::1] = np.cos(angles[:, 0::1])\n",
        "    pos_encoding = angles[np.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)"
      ],
      "metadata": {
        "id": "5kDjoq6lBhBA"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_positional_embedding(10, 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmIXkSZFBvG1",
        "outputId": "c30f4ad0-1477-46f0-d6f9-1fa1c1996f62"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 10, 1), dtype=float32, numpy=\n",
              "array([[[1.        ],\n",
              "        [0.66636676],\n",
              "        [0.9998    ],\n",
              "        [0.99955016],\n",
              "        [0.99999994],\n",
              "        [0.9999999 ],\n",
              "        [1.        ],\n",
              "        [1.        ],\n",
              "        [1.        ],\n",
              "        [1.        ]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder Layer"
      ],
      "metadata": {
        "id": "0s6rd5DXBx2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, embedding_dims, num_heads,\n",
        "                  fully_connected_dim, dropout_rate = 0.1, \n",
        "                  layernorm_eps = 1e-6):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        \n",
        "        self.mha = tf.keras.layers.MultiHeadAttention(num_heads,\n",
        "                                                      key_dim = embedding_dims,\n",
        "                                                      dropout = dropout_rate)\n",
        "        \n",
        "        self.ffn = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(fully_connected_dim, activation='relu'),\n",
        "        tf.keras.layers.Dense(embedding_dims)])\n",
        "        \n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon = layernorm_eps)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon = layernorm_eps)\n",
        "        self.dropout_ffn = tf.keras.layers.Dropout(dropout_rate)\n",
        "        \n",
        "    def call(self, x, training = False):\n",
        "        attn_out = self.mha(x, x, x, training = training)\n",
        "        attn_out = self.layernorm1(x + attn_out)\n",
        "        ffn_out = self.ffn(attn_out)\n",
        "        ffn_out = self.layernorm2(attn_out + ffn_out)\n",
        "        return ffn_out"
      ],
      "metadata": {
        "id": "U3PmadrwBwsl"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder"
      ],
      "metadata": {
        "id": "s7Ng9G6fB1ne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, input_vocab_size, embedding_dims, num_heads,\n",
        "                 fully_connected_dim, max_position_encoding, pretrained_embedding_matrix = None,\n",
        "                 dropout_rate = 0.1, layernorm_eps = 1e-6):\n",
        "        super(Encoder, self).__init__()\n",
        "        \n",
        "        self.embedding_dims = embedding_dims\n",
        "        \n",
        "        \n",
        "        self.embeddings = tf.keras.layers.Embedding(input_vocab_size, self.embedding_dims)\n",
        "        if pretrained_embedding_matrix is not None:\n",
        "            self.embeddings.embeddings_initializer = tf.keras.initializers.constant(pretrained_embedding_matrix)\n",
        "            self.embeddings.trainable = False\n",
        "        \n",
        "        self.positional_encoding = get_positional_embedding(max_position_encoding, self.embedding_dims)\n",
        "        self.encoding_layer = EncoderLayer(embedding_dims, num_heads,\n",
        "                  fully_connected_dim, dropout_rate = dropout_rate, \n",
        "                  layernorm_eps = layernorm_eps)\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "    \n",
        "    def call(self, x, training = False):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        \n",
        "        x = self.embeddings(x)\n",
        "        \n",
        "        ## Scaling the embeddings\n",
        "        x *= tf.math.sqrt(tf.cast(self.embedding_dims, tf.float32))\n",
        "        \n",
        "        ## Adding the Positional Encoding to embeddings\n",
        "        x += self.positional_encoding[:, :seq_len, :]\n",
        "        x = self.dropout(x, training = training)\n",
        "        \n",
        "        x = self.encoding_layer(x, training = training)\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "t9dTQW6rB3au"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FullyConnectedLayer(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(FullyConnectedLayer, self).__init__()\n",
        "\n",
        "        self.conv1 = tf.keras.layers.Conv1D(64, kernel_size = 8, strides = 4)\n",
        "        self.conv2 = tf.keras.layers.Conv1D(128, kernel_size = 8, strides = 4)\n",
        "        self.conv3 = tf.keras.layers.Conv1D(256, kernel_size = 8, strides = 4)\n",
        "\n",
        "        self.maxpool1 = tf.keras.layers.MaxPooling1D()\n",
        "        self.maxpool2 = tf.keras.layers.MaxPooling1D()\n",
        "        self.maxpool3 = tf.keras.layers.MaxPooling1D()\n",
        "\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.dense1 = tf.keras.layers.Dense(32, activation = 'relu')\n",
        "        self.output_layer = tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "        \n",
        "    def call(self, encoder_out):\n",
        "        x = self.conv1(encoder_out)\n",
        "        x = self.maxpool1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.maxpool2(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.maxpool3(x)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        x = self.dense1(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "U4KQHYO1Okzq"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Machine Learning Model"
      ],
      "metadata": {
        "id": "X0ud8mQGB6Ku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Mymodel(input_shape, input_vocab_size, embedding_dims, embedding_matrix = None):\n",
        "    input_x = tf.keras.layers.Input(shape = input_shape)\n",
        "    encoder_out = Encoder(input_vocab_size = input_vocab_size,\n",
        "                      embedding_dims = embedding_dims,\n",
        "                      num_heads = 5,\n",
        "                     fully_connected_dim = 128,\n",
        "                      max_position_encoding = input_shape, pretrained_embedding_matrix = embedding_matrix,\n",
        "                     dropout_rate = 0.1, layernorm_eps = 1e-6\n",
        "        )(input_x)\n",
        "\n",
        "    outputs = FullyConnectedLayer()(encoder_out)\n",
        "    model = tf.keras.Model(inputs = input_x, outputs = outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "fEEbHECLB981"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Training Loop"
      ],
      "metadata": {
        "id": "TRv7moS_CShG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    model = Mymodel(MAX_SEQ_LEN, VOCAB_SIZE, EMB_DIMS, EMBEDDING_MATRIX)\n",
        "\n",
        "    loss_object = tf.keras.losses.BinaryCrossentropy(reduction = tf.keras.losses.Reduction.NONE)\n",
        "\n",
        "    def compute_loss(labels, predictions):\n",
        "        per_example_loss = loss_object(labels, predictions)\n",
        "        return tf.nn.compute_average_loss(per_example_loss, global_batch_size = BATCH_SIZE * strategy.num_replicas_in_sync)\n",
        "\n",
        "    test_loss = tf.keras.metrics.Mean(name = \"test_loss\")\n",
        "    train_accuracy = tf.keras.metrics.BinaryAccuracy(name = \"train_accuracy\")\n",
        "    test_accuracy = tf.keras.metrics.BinaryAccuracy(name = \"test_accuracy\")\n",
        "\n",
        "    lr_scheduler = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "        initial_learning_rate = 0.001,\n",
        "        decay_steps =500,\n",
        "        decay_rate = 0.9\n",
        "    )\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate = lr_scheduler)\n",
        "\n",
        "    @tf.function\n",
        "    def distributed_training_step(datasets_inputs):\n",
        "        per_replica_losses = strategy.run(train_steps, args = (datasets_inputs, ))\n",
        "        print(per_replica_losses)\n",
        "        return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis = None)\n",
        "    \n",
        "    @tf.function\n",
        "    def distributed_test_step(datasets_inputs):\n",
        "        strategy.run(test_steps, args = (datasets_inputs, ))\n",
        "    \n",
        "    \n",
        "    def train_steps(inputs):\n",
        "        text_seq, labels = inputs\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = model(text_seq)\n",
        "            loss = compute_loss(labels, predictions)\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "        train_accuracy.update_state(labels, predictions)\n",
        "        return loss\n",
        "\n",
        "    def test_steps(inputs):\n",
        "        text_seq, labels = inputs\n",
        "        predictions = model(text_seq)\n",
        "        loss = loss_object(labels, predictions)\n",
        "\n",
        "        test_loss.update_state(loss)\n",
        "        test_accuracy.update_state(labels, predictions)"
      ],
      "metadata": {
        "id": "3UMM7S8lCVSF"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1NuF5frLpvt",
        "outputId": "78f98709-a8b6-4034-9097-ba17358db990"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_12 (InputLayer)       [(None, 1024)]            0         \n",
            "                                                                 \n",
            " encoder_11 (Encoder)        (None, 1024, 300)         31652828  \n",
            "                                                                 \n",
            " fully_connected_layer_2 (Fu  (None, 1)                489985    \n",
            " llyConnectedLayer)                                              \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32,142,813\n",
            "Trainable params: 2,373,213\n",
            "Non-trainable params: 29,769,600\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 5\n",
        "with strategy.scope():\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        epoch_start = datetime.now()\n",
        "        total_loss = 0.0\n",
        "        num_batches = 0\n",
        "\n",
        "        # Training Loop\n",
        "        for x in train_dataset: \n",
        "            total_loss += distributed_training_step(x)\n",
        "            num_batches += 1\n",
        "\n",
        "        train_loss = total_loss / num_batches\n",
        "\n",
        "        # Testing Loop\n",
        "        for x in val_dataset:\n",
        "            distributed_test_step(x)\n",
        "\n",
        "        epoch_end = datetime.now()\n",
        "        \n",
        "        template = (\"Epoch {}, Loss: {:.2f}, Accuracy: {:.2f}, Test Loss: {:.2f}, Test Accuracy: {:.2f}, \\t Elapsed Time: {}\")\n",
        "\n",
        "        print(template.format(\n",
        "            epoch + 1,\n",
        "            train_loss,\n",
        "            train_accuracy.result() * 100,\n",
        "            test_loss.result() / strategy.num_replicas_in_sync,\n",
        "            test_accuracy.result() * 100,\n",
        "            (epoch_end - epoch_start).seconds\n",
        "        ))\n",
        "\n",
        "        test_loss.reset_states()\n",
        "        train_accuracy.reset_states()\n",
        "\n",
        "        test_accuracy.reset_states()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AHw9L_LNLANF",
        "outputId": "869b43f3-d048-4a14-8fc1-d5f6a107e06f"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PerReplica:{\n",
            "  0: Tensor(\"output_0_shard_0:0\", shape=(), dtype=float32),\n",
            "  1: Tensor(\"output_0_shard_1:0\", shape=(), dtype=float32),\n",
            "  2: Tensor(\"output_0_shard_2:0\", shape=(), dtype=float32),\n",
            "  3: Tensor(\"output_0_shard_3:0\", shape=(), dtype=float32),\n",
            "  4: Tensor(\"output_0_shard_4:0\", shape=(), dtype=float32),\n",
            "  5: Tensor(\"output_0_shard_5:0\", shape=(), dtype=float32),\n",
            "  6: Tensor(\"output_0_shard_6:0\", shape=(), dtype=float32),\n",
            "  7: Tensor(\"output_0_shard_7:0\", shape=(), dtype=float32)\n",
            "}\n",
            "PerReplica:{\n",
            "  0: Tensor(\"output_0_shard_0:0\", shape=(), dtype=float32),\n",
            "  1: Tensor(\"output_0_shard_1:0\", shape=(), dtype=float32),\n",
            "  2: Tensor(\"output_0_shard_2:0\", shape=(), dtype=float32),\n",
            "  3: Tensor(\"output_0_shard_3:0\", shape=(), dtype=float32),\n",
            "  4: Tensor(\"output_0_shard_4:0\", shape=(), dtype=float32),\n",
            "  5: Tensor(\"output_0_shard_5:0\", shape=(), dtype=float32),\n",
            "  6: Tensor(\"output_0_shard_6:0\", shape=(), dtype=float32),\n",
            "  7: Tensor(\"output_0_shard_7:0\", shape=(), dtype=float32)\n",
            "}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-59fcbbdb2312>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# Training Loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdistributed_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mnum_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7184\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7185\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7186\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: 9 root error(s) found.\n  (0) RESOURCE_EXHAUSTED: {{function_node __inference_distributed_training_step_13648}} Attempting to reserve 6.66G at the bottom of memory. That was not possible. There are 7.21G free, 0B reserved, and 5.82G reservable.\n\t [[{{node cluster_distributed_training_step/_execute_4_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED: {{function_node __inference_distributed_training_step_13648}} Attempting to reserve 6.66G at the bottom of memory. That was not possible. There are 7.21G free, 0B reserved, and 5.82G reservable.\n\t [[{{node cluster_distributed_training_step/_execute_2_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[cluster_distributed_training_step/_execute_3_0/_111]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (2) RESOURCE_EXHAUSTED: {{function_node __inference_distributed_training_step_13648}} Attempting to reserve 6.66G at the bottom of memory. That was not possible. There are 7.21G free, 0B reserved, and 5.82G reservable.\n\t [[{{node cluster_distributed_training_step/_execute_2_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (3) CANCELLED: {{function_node __inference_distributed_training_step_13648}} RPC cancelled, not running TPU program on device 7\n\t [[{{node cluster_distributed_training_step/_execute_7_0}}]]\n  (4) CANCELLED: {{function_node __inference_distributed_training_step_13648}} RPC cancelled, not running TPU program on device 6\n\t [[{{node cluster_distributed_training_step/_execute_6_0}}]]\n  (5) CANCELLED: {{function_node __inference_distributed_training_step_13648}} RPC cancelled, not running TPU program on device 5\n\t [[{{node cluster_distributed_training_step/_execute_5_0}}]]\n  (6) CANCELLED: {{function_node __inference_distributed_training_step_13648}} RPC cancelled, not running TPU program on device 3\n\t [[{{node cluster_distributed_training_step/_execute_3_0}}]]\n  (7) CANCELLED: {{function_node __inference_distributed_training_step_13648}} RPC cancelled, not running TPU program on device 1\n\t [[{{node cluster_distributed_training_step/_execute_1_0}}]]\n  (8) CANCELLED: {{function_node __inference_distributed_training_step_13648}} RPC cancelled, not running TPU program on device 0\n\t [[{{node cluster_distributed_training_step/_execute_0_0}}]]\n0 successful operations.\n0 derived errors ignored. [Op:AddV2]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "te = None\n",
        "lab = None\n",
        "for text, label in train_dataset.take(1):\n",
        "    te = text\n",
        "    lab = label"
      ],
      "metadata": {
        "id": "tczZ3O-aSyTT"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Tyck35AT-zS",
        "outputId": "40524be4-e33c-474a-91d5-b732c35c9f5f"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128,), dtype=int64, numpy=\n",
              "array([1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
              "       1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
              "       1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1])>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    }
  ]
}